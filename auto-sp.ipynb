{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all files...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load car and not car data\n",
    "cars = []\n",
    "not_cars = []\n",
    "\n",
    "# Get car paths\n",
    "car_paths = [\"./udacity-dataset/vehicles/GTI_Far\"\n",
    "\"./udacity-dataset/vehicles/GTI_Left\",\n",
    "\"./udacity-dataset/vehicles/GTI_MiddleClose\",\n",
    "\"./udacity-dataset/vehicles/GTI_Right\",\n",
    "\"./udacity-dataset/vehicles/KITTI_extracted\"]\n",
    "\n",
    "for i in xrange(0, len(car_paths)):\n",
    "    car_path = car_paths[i]\n",
    "    for file in glob.glob(os.path.join(car_path, \"*.png\")):\n",
    "        cars.append(file)\n",
    "\n",
    "# Get not car paths\n",
    "not_car_paths = [\"./udacity-dataset/non-vehicles/Extras\",\n",
    "\"./udacity-dataset/non-vehicles/GTI\"]\n",
    "\n",
    "for i in xrange(0, len(not_car_paths)):\n",
    "    not_car_path = not_car_paths[i]\n",
    "    for file in glob.glob(os.path.join(not_car_path, \"*.png\")):\n",
    "        not_cars.append(file)\n",
    "\n",
    "print \"Loaded all files...\"\n",
    "        \n",
    "# Extract HOG for features\n",
    "def extract_hog_features(img, channel=0, orientations=9, pixels_per_cell=8, cells_per_block=2, transform_sqrt=False, visualise=False, feature_vector=True):\n",
    "    if channel == \"ALL\":\n",
    "        for j in xrange(0, img.shape[2]):\n",
    "            hog_features = hog(img[:,:,j], orientations=orientations, pixels_per_cell=(pixels_per_cell, pixels_per_cell), cells_per_block=(cells_per_block, cells_per_block), transform_sqrt=transform_sqrt, visualise=visualise, feature_vector=feature_vector)\n",
    "            hog_features = np.ravel(hog_features)\n",
    "            print hog_features\n",
    "    else:\n",
    "        hog_features = hog(img[:,:,channel], orientations=orientations, pixels_per_cell=(pixels_per_cell, pixels_per_cell), cells_per_block=(cells_per_block, cells_per_block), transform_sqrt=transform_sqrt, visualise=visualise, feature_vector=feature_vector)\n",
    "\n",
    "    return hog_features\n",
    "\n",
    "def extract_bin_spacial_features(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).ravel()\n",
    "\n",
    "\n",
    "def extract_color_hist_features(image, nbins=32, bins_range=(0,256)):\n",
    "\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(image[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(image[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(image[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_training_features(files, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_features, hog_features):\n",
    "    features = []\n",
    "\n",
    "    for file in files:\n",
    "        file_features = []\n",
    "        image = cv2.imread(file)\n",
    "        if spatial_feat:\n",
    "            file_features.append(extract_bin_spacial_features(image))\n",
    "        if hist_features:\n",
    "            file_features.append(extract_color_hist_features(image))\n",
    "        if hog_features:\n",
    "            file_features.append(extract_hog_features(image))\n",
    "\n",
    "        features.append(np.concatenate(file_features))\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_features(image, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_features, hog_features):\n",
    "    \n",
    "    file_features = []\n",
    "    \n",
    "    if spatial_feat:\n",
    "        file_features.append(extract_bin_spacial_features(image))\n",
    "    if hist_features:\n",
    "        file_features.append(extract_color_hist_features(image))\n",
    "    if hog_features:\n",
    "        file_features.append(extract_hog_features(image))\n",
    "        \n",
    "    return np.concatenate(file_features)\n",
    "\n",
    "\n",
    "def normalize_features(raw_features):\n",
    "    normalized_features = []\n",
    "    return normalized_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done extracting features\n"
     ]
    }
   ],
   "source": [
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 16 # HOG pixels per cell #16\n",
    "cell_per_block = 1 # HOG cells per block #2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [300, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "\n",
    "# car_features = extract_training_features(cars, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "#                                     spatial_feat, hist_feat, hog_feat)\n",
    "\n",
    "# not_car_features = extract_training_features(not_cars, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "#                                     spatial_feat, hist_feat, hog_feat)\n",
    "\n",
    "print \"done extracting features\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f590d2b8eeda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# X = np.vstack((car_features, not_car_features)).astype(np.float64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit a per-column scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the scaler to X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscaled_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Configured Using:', 9, 'orientations', 16, 'pixels per cell and', 1, 'cells per block')\n",
      "('Feature vector length:', 1764)\n",
      "11.57742 seconds to train classifier...\n",
      "('Test Accuracy of SVC = ', 0.9535)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print ('Configured Using:',orient,'orientations',\n",
    "       pix_per_cell, 'pixels per cell and', cell_per_block,'cells per block')\n",
    "print ('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "t1 = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print (\"{} seconds to train classifier...\".format(round(t2-t1, 5)))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sliding_windows(img, x_range, y_range, window_size, xy_overlap_percent):\n",
    "    windows = []\n",
    "    \n",
    "    x_start = x_range[0];\n",
    "    x_end = x_range[1];\n",
    "    y_start = y_range[0];\n",
    "    y_end = y_range[1];\n",
    "    \n",
    "    # check values and use full image size if parameter is not given\n",
    "    if (x_start == None):\n",
    "        x_start = 0;\n",
    "    if (x_end == None):\n",
    "        x_end = img.shape[1];\n",
    "    if (y_start == None):\n",
    "        y_start = 0;\n",
    "    if (y_end == None):\n",
    "        y_end = img.shape[0];\n",
    "\n",
    "    # window span\n",
    "    x_span = x_end - x_start;\n",
    "    y_span = y_end - y_start;\n",
    "\n",
    "    # how much to move the window by each step\n",
    "    x_step_size = window_size[0] * (1 - xy_overlap_percent[0])\n",
    "    y_step_size = window_size[1] * (1 - xy_overlap_percent[1])\n",
    "\n",
    "    # the region that overlaps\n",
    "    x_overlap_region = window_size[0] * xy_overlap_percent[0]\n",
    "    y_overlap_region = window_size[1] * xy_overlap_percent[1]\n",
    "\n",
    "    # num of times the window fits in the span\n",
    "    x_num_steps = np.int((x_span - x_overlap_region) / x_step_size)\n",
    "    y_num_steps = np.int((y_span - y_overlap_region) / y_step_size)\n",
    "\n",
    "    for y in range(y_num_steps):\n",
    "        for x in range(x_num_steps):\n",
    "            window_start = (np.int(x * x_step_size + x_start), np.int(y * y_step_size + y_start))\n",
    "            window_end = (np.int(window_start[0] + window_size[0]), np.int(window_start[1] + window_size[1]))\n",
    "            windows.append((window_start, window_end))\n",
    "        \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "def get_classified_windows(image):\n",
    "    # Returns windows that classifier claims to be a car\n",
    "    \n",
    "    xy_window = [(64,64), (96,96), (128,128), (256,256)]\n",
    "#     xy_window = [(32,32), (64,64), (128,128), (256,256)]\n",
    "    y_start_stop = [[300, 450], [300, 450], [300, None], [300, None]]\n",
    "\n",
    "    windows_temp = []\n",
    "    for i in range(len(xy_window)):\n",
    "        windows = sliding_windows(image, [None, None], y_start_stop[i], \n",
    "                            xy_window[i], (0.75, 0.75))\n",
    "        windows = search_windows(image, windows, None, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "                                        spatial_feat, hist_feat, hog_feat)\n",
    "        windows_temp.append(windows)\n",
    "\n",
    "    #Flatten windows_temp\n",
    "    windows_final = sum(windows_temp, [])\n",
    "    return windows_final\n",
    "\n",
    "\n",
    "# image = cv2.imread(\"test.jpeg\")\n",
    "# heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "# classified_windows = get_classified_windows(image)\n",
    "# heatmap = apply_heat(heatmap, classified_windows)\n",
    "# labels = label(heatmap)\n",
    "# final_image = draw_cars(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), labels)\n",
    "# window_img = draw_boxes(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), classified_windows, color=(0, 0, 255), thick=6)\n",
    "# heatmap_image = np.clip(heatmap, 0, 255)\n",
    "\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     print \"plotting image...\"\n",
    "#     fig = plt.figure(figsize=(20, 20))\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(window_img)\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(heatmap_image, cmap='hot')\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1771b1c94c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mclf_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scaler\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'trainer'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print \"start\"\n",
    "\n",
    "X_scaler = None\n",
    "clf_g = None\n",
    "\n",
    "with open(\"classifier.p\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    clf_g = data[\"classifier\"]\n",
    "    X_scaler = data[\"scaler\"]\n",
    "    \n",
    "\n",
    "\n",
    "def search_windows(img, windows, clf, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_features, hog_features):\n",
    "    on_windows = []\n",
    "\n",
    "        \n",
    "    for window in windows:\n",
    "        startx = window[0][0]\n",
    "        starty = window[0][1]\n",
    "        endx = window[1][0]\n",
    "        endy = window[1][1]\n",
    "\n",
    "        cropped = img[starty:endy, startx:endx]\n",
    "\n",
    "        test_img = cv2.resize(cropped, (64, 64))\n",
    "        features = extract_features(test_img, spatial_size=spatial_size, hist_bins=hist_bins, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, spatial_feat=spatial_feat, hist_features=hist_features, hog_features=hog_features)\n",
    "\n",
    "        # transform features to be fed into classifier\n",
    "        test_features = X_scaler.transform(np.array(features).reshape(1, -1))\n",
    "        prediction = clf_g.N.forward(test_features)\n",
    "\n",
    "        if prediction > 0.1:\n",
    "            on_windows.append(window)\n",
    "\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "# Heat values must be over threshold to be valid\n",
    "HEAT_THRESHOLD = 2\n",
    "\n",
    "\n",
    "def apply_heat(heatmap, windows):\n",
    "    \n",
    "    for window in windows:\n",
    "        startx, starty = window[0][0], window[0][1]\n",
    "        endx, endy = window[1][0], window[1][1]\n",
    "        # Add heat value of 1 to all pixels inside classified 'true' window\n",
    "        heatmap[starty:endy, startx:endx] += 1\n",
    "    \n",
    "    # Use threshold to zero out values\n",
    "    heatmap[heatmap <= HEAT_THRESHOLD] = 0\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def draw_cars(img, labels):\n",
    "    # Labels contains ([Image Array], number of heat blobs)\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Get pixels for the corresponding labeled heat\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Get the boundary of the heat\n",
    "        outline = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, outline[0], outline[1], (0,0,255), 6)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video vehicle_detection.mp4\n",
      "[MoviePy] Writing video vehicle_detection.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 300/301 [02:30<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: vehicle_detection.mp4 \n",
      "\n",
      "CPU times: user 2min 26s, sys: 1.18 s, total: 2min 27s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def process_frame(image):\n",
    "    heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    classified_windows = get_classified_windows(image)\n",
    "    heatmap = apply_heat(heatmap, classified_windows)\n",
    "    labels = label(heatmap)\n",
    "    final_image = draw_cars(image, labels)\n",
    "    return final_image\n",
    "\n",
    "\n",
    "video = \"datasets/Sunny/april21.avi\"\n",
    "video = VideoFileClip(video)\n",
    "\n",
    "\n",
    "detection_video = video.fl_image(process_frame)\n",
    "%time detection_video.write_videofile(\"vehicle_detection.mp4\", audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 10 frame test\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-39de280887d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclassified_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classified_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_heat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassified_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6558310096f8>\u001b[0m in \u001b[0;36mget_classified_windows\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     31\u001b[0m                             xy_window[i], (0.75, 0.75))\n\u001b[1;32m     32\u001b[0m         windows = search_windows(image, windows, None, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n\u001b[0;32m---> 33\u001b[0;31m                                         spatial_feat, hist_feat, hog_feat)\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwindows_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-06122195bd81>\u001b[0m in \u001b[0;36msearch_windows\u001b[0;34m(img, windows, clf, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_features, hog_features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# transform features to be fed into classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "print \"starting 10 frame test\"\n",
    "\n",
    "video = \"datasets/Sunny/april21.avi\"\n",
    "# video = \"datasets/Urban/march9.avi\"\n",
    "video = VideoFileClip(video)\n",
    "\n",
    "frames = []\n",
    "for i in range(10):\n",
    "    frame_name = \"frame{}.jpeg\".format(i)\n",
    "    video.save_frame(frame_name, t=i)\n",
    "    frames.append(frame_name)\n",
    "\n",
    "\n",
    "final_images = []\n",
    "window_images = []\n",
    "for frame in frames:\n",
    "    img = cv2.imread(frame)\n",
    "    heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    classified_windows = get_classified_windows(img)\n",
    "    heatmap = apply_heat(heatmap, classified_windows)\n",
    "    labels = label(heatmap)\n",
    "    final_image = draw_cars(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), labels)\n",
    "    window_img = draw_boxes(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), classified_windows, color=(0, 0, 255), thick=6)\n",
    "    \n",
    "    final_images.append(final_image)\n",
    "    window_images.append(window_img)\n",
    "\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    print \"plotting image...\"\n",
    "\n",
    "    for i in xrange(len(frames)):\n",
    "        fig = plt.figure(i, figsize=(20,20))\n",
    "        plt.title('Frame: {}'.format(frames[i]))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(final_images[i])\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(window_images[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
